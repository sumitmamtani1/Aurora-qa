# ğŸŒŒ Aurora-QA: Natural Language Question Answering API

_A lightweight Flask-based service that answers natural-language questions about member activity data fetched from a public API._

---

## ğŸš€ Overview

**Aurora-QA** is a simple, rule-based **Question Answering (QA)** service built using **Flask** and **Python**.  
It allows users to ask natural-language questions like:

- â€œWhen is Layla planning her trip to London?â€
- â€œHow many cars does Vikram Desai have?â€
- â€œWhat are Amiraâ€™s favorite restaurants?â€

The service infers answers from real messages fetched via the public API:

> ğŸ›°ï¸ **Public Data Source:** [https://november7-730026606190.europe-west1.run.app/messages](https://november7-730026606190.europe-west1.run.app/messages)

---

## âœ¨ Example Queries

| Example Question | Example Answer |
|------------------|----------------|
| â€œWhen is Layla planning her trip to London?â€ | `Layla Kawaguchi mentioned travel: "Please remember I prefer aisle seats during my flights."` |
| â€œHow many cars does Vikram Desai have?â€ | `Vikram Desai mentions cars: "The car service was impeccableâ€”thank you for your recommendation."` |
| â€œWhat are Amiraâ€™s favorite restaurants?â€ | `Amira Khan: The French Laundry, Le Bernardin` |

---

## ğŸ§ª Example API Queries (with JSON Responses)

### 1ï¸âƒ£ Laylaâ€™s Trip Query

**Request:**
GET https://aurora-qa.onrender.com/ask?q=When%20is%20Layla%20planning%20her%20trip%20to%20London


**Response:**
```json
{
  "answer": "Layla Kawaguchi mentioned travel: 'Please remember I prefer aisle seats during my flights.'"
}
2ï¸âƒ£ Vikramâ€™s Cars Query
Request:

GET https://aurora-qa.onrender.com/ask?q=How%20many%20cars%20does%20Vikram%20Desai%20have
Response:

{
  "answer": "Vikram Desai mentions cars: 'The car service was impeccableâ€”thank you for your recommendation.'"
}
3ï¸âƒ£ Amiraâ€™s Favorite Restaurants
Request:

GET https://aurora-qa.onrender.com/ask?q=What%20are%20Amira%27s%20favorite%20restaurants
Response:


{
  "answer": "Amira Khan: The French Laundry, Le Bernardin"
}
âš™ï¸ Setup & Run Instructions
ğŸ§© Prerequisites
Python 3.9+

pip installed

Internet connection (to access the public API)


# 1. Clone the repository
git clone https://github.com/sumitmamtani1/Aurora-qa.git
cd Aurora-qa

# 2. Install dependencies
pip install -r requirements.txt

# 3. Start the Flask server
python app.py
Once running, visit:
ğŸ‘‰ http://127.0.0.1:8080/ask?q=When%20is%20Layla%20planning%20her%20trip%20to%20London

Response:

{"answer": "Layla Kawaguchi mentioned travel: 'Please remember I prefer aisle seats during my flights.'"}
ğŸ³ Run via Docker

# Build image
docker build -t aurora-qa .

# Run container
docker run -p 8080:8080 -e MESSAGES_API_URL="https://november7-730026606190.europe-west1.run.app/messages" aurora-qa
Then open in your browser:


http://127.0.0.1:8080/ask?q=What%20are%20Amira%27s%20favorite%20restaurants
â˜ï¸ Deploy to Render (Free Cloud Hosting)
Push this repo to GitHub.

Go to https://render.com â†’ New Web Service.

Connect your GitHub repo Aurora-qa.

Render auto-detects your Dockerfile.

Add environment variable:

MESSAGES_API_URL=https://november7-730026606190.europe-west1.run.app/messages
Click Deploy â€” wait for build & deploy to complete.

Test your endpoint:


https://aurora-qa.onrender.com/ask?q=When%20is%20Layla%20planning%20her%20trip%20to%20London
ğŸ§  How It Works
The /ask endpoint receives a user question.

The system fetches all member messages from the public API.

It parses text using keyword extraction, regex, and fuzzy name matching.

Based on detected intent (e.g., travel, restaurants, cars), it constructs an inferred answer.

Returns a concise JSON response.

ğŸ§© API Endpoints
Method	Endpoint	Description
GET	/ask?q=<question>	Returns a JSON answer inferred from messages
GET	/health	Health check endpoint

Example Response:

{ "answer": "Layla Kawaguchi mentioned travel: 'Please remember I prefer aisle seats during my flights.'" }
ğŸ’¡ Alternative Approaches Considered
1ï¸âƒ£ Rule-Based Parsing (Chosen Approach)
Lightweight, explainable, and fast.

Uses regex and fuzzy matching to extract relevant text segments.

Detects structured entities like names, dates, numbers, and keywords.

Simple, interpretable, and easy to maintain.

âœ… Pros: Deterministic and transparent
âš ï¸ Cons: Requires specific phrasing; limited flexibility

2ï¸âƒ£ Embedding-Based Semantic Search
Uses embeddings (e.g., Sentence-BERT) to match queries with semantically similar messages.

Converts messages into vector embeddings and retrieves the top similar ones.

Understands synonyms and paraphrases.

âœ… Pros: Handles natural phrasing
âš ï¸ Cons: Requires vector DB (e.g., FAISS, Pinecone); adds latency

3ï¸âƒ£ Prompt-Based LLM Reasoning
Integrates an LLM (e.g., GPT-3.5) to reason over the message dataset.

Sends relevant messages + question to a language model for natural reasoning.

Returns human-like, context-aware answers.

âœ… Pros: Very flexible and natural
âš ï¸ Cons: Non-deterministic, slower, requires API cost

4ï¸âƒ£ Hybrid (Semantic + Rule-Based) Approach
Combines semantic retrieval with structured extraction.

Embedding retrieval for candidate messages

Regex-based parsing for final structured answer

âœ… Pros: High accuracy and interpretability
âš ï¸ Cons: More complex architecture

ğŸ” Bonus: Data Insights
Insight	Observation
ğŸ•‘ Dataset Size	~3,349 messages retrieved from the public API.
ğŸ‘¤ Top Members	Layla Kawaguchi, Vikram Desai, Sophia Al-Farsi, Hans MÃ¼ller.
ğŸ½ï¸ Restaurant Mentions	Common: The French Laundry, Le Bernardin, Nobu.
ğŸš— Car Mentions	Many reference â€œcar serviceâ€ â€” not ownership, requiring nuanced handling.
ğŸ§³ Travel Patterns	Frequent destinations include London, Paris, Monaco, Bangkok.

ğŸ§­ Future Enhancements
Add semantic retrieval for natural query flexibility

Integrate LLM fallback for complex reasoning

Cache data for faster response time

Add interactive frontend visualization

ğŸ‘¨â€ğŸ’» Author
Sumit Mamtani
â­ If you found this project useful, please star the repository! â­
